{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e325e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5847f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read: Combined_Coinbase_Pro_2017_2022 (1).csv\n",
      "\n",
      "First 5 rows:\n",
      "  portfolio        type                      time    amount   balance  \\\n",
      "0   default     deposit  2017-10-06T23:13:16.522Z  5.000000  5.000000   \n",
      "1   default  withdrawal  2017-10-12T19:59:32.871Z -5.000000  0.000000   \n",
      "2   default     deposit  2017-10-15T16:47:59.962Z  4.745679  4.745679   \n",
      "3   default       match  2017-10-15T21:12:18.513Z -0.805657  3.940022   \n",
      "4   default       match  2017-10-15T21:12:18.513Z  0.048339  0.048339   \n",
      "\n",
      "  amount/balance unit                           transfer id   trade id  \\\n",
      "0                 ETH  f73e7752-3b7b-4f0d-9ee7-da3cbd6819cc        NaN   \n",
      "1                 ETH  42cfa1e3-344c-4ba3-ba5f-a5dee3891b1c        NaN   \n",
      "2                 ETH  7434eb10-9dd5-4a52-83fa-36af796e16f6        NaN   \n",
      "3                 ETH                                   NaN  1641117.0   \n",
      "4                 BTC                                   NaN  1641117.0   \n",
      "\n",
      "                               order id  \n",
      "0                                   NaN  \n",
      "1                                   NaN  \n",
      "2                                   NaN  \n",
      "3  63c5fa59-3b73-40cb-a48e-211e6e321a9e  \n",
      "4  63c5fa59-3b73-40cb-a48e-211e6e321a9e  \n",
      "\n",
      "Columns and their data types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1641 entries, 0 to 1640\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   portfolio            1641 non-null   object \n",
      " 1   type                 1641 non-null   object \n",
      " 2   time                 1641 non-null   object \n",
      " 3   amount               1641 non-null   float64\n",
      " 4   balance              1641 non-null   float64\n",
      " 5   amount/balance unit  1641 non-null   object \n",
      " 6   transfer id          119 non-null    object \n",
      " 7   trade id             1494 non-null   float64\n",
      " 8   order id             1494 non-null   object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 115.5+ KB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      "portfolio                 0\n",
      "type                      0\n",
      "time                      0\n",
      "amount                    0\n",
      "balance                   0\n",
      "amount/balance unit       0\n",
      "transfer id            1522\n",
      "trade id                147\n",
      "order id                147\n",
      "dtype: int64\n",
      "['portfolio', 'type', 'time', 'amount', 'balance', 'amount/balance unit', 'transfer id', 'trade id', 'order id']\n"
     ]
    }
   ],
   "source": [
    "def read_and_inspect_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully read: {file_path}\")\n",
    "        print(\"\\nFirst 5 rows:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nColumns and their data types:\")\n",
    "        print(df.info())\n",
    "        print(\"\\nMissing values per column:\")\n",
    "        print(df.isnull().sum())\n",
    "        columns = df.columns.tolist()\n",
    "        print(columns)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "df_input = read_and_inspect_csv(\"Combined_Coinbase_Pro_2017_2022 (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c7bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Trade ID', 'Imported From', 'Add Date', 'Date']\n"
     ]
    }
   ],
   "source": [
    "file = \"CoinTracking Standard csv format.csv\"\n",
    "df = pd.read_csv(file)\n",
    "target_labels = df.columns.tolist() \n",
    "# Cur. is Buy Currency, Cur..1 is Sell Currency, Cur..2 is Fee Currency\n",
    "print(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de69c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Configuration for Coinbase Pro (Updated) ---\n",
    "coinbase_pro_config = {\n",
    "    \"platform_name\": \"Coinbase Pro\",\n",
    "    \"consolidation_style\": \"by_trade_id_and_time\", # Use the leg-based consolidation\n",
    "    \"identification_headers\": [\"portfolio\", \"type\", \"time\", \"amount\", \"balance\"],\n",
    "    \"column_mapping\": {\n",
    "        \"time\": \"DateTime_Raw\",\n",
    "        \"type\": \"Transaction_Type_Raw\",\n",
    "        \"amount\": \"Amount_Raw\",\n",
    "        \"amount/balance unit\": \"Currency_Raw\",\n",
    "        \"trade id\": \"Trade_ID_Raw\",\n",
    "        \"order id\": \"Order_ID_Raw\",\n",
    "        \"transfer id\": \"Transfer_ID_Raw\",\n",
    "        \"portfolio\": \"Portfolio_Raw\"\n",
    "    },\n",
    "    \"static_values\": {\n",
    "        \"Exchange\": \"Coinbase Pro\",\n",
    "        \"Imported From\": \"Coinbase Pro CSV\",\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "    \"transformations\": {\n",
    "        \"Date\": {\"source\": \"DateTime_Raw\", \"action\": \"extract_datetime_combined\"},\n",
    "        \"Type\": {\"source\": \"Transaction_Type_Raw\", \"action\": \"map_transaction_type\"},\n",
    "        \"Buy\": {\"source\": [\"Transaction_Type_Raw\", \"Amount_Raw\"], \"action\": \"get_buy_amount_from_leg\"},\n",
    "        \"Sell\": {\"source\": [\"Transaction_Type_Raw\", \"Amount_Raw\"], \"action\": \"get_sell_amount_from_leg\"},\n",
    "        \"Fee\": {\"source\": [\"Transaction_Type_Raw\", \"Amount_Raw\"], \"action\": \"get_fee_amount_from_leg\"},\n",
    "        \"Trade ID\": {\"source\": \"Trade_ID_Raw\", \"action\": \"passthrough\"},\n",
    "        \"Group\": {\"source\": \"Portfolio_Raw\", \"action\": \"passthrough\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- NEW: Bitcoin.tax Config (Handles pre-consolidated rows) ---\n",
    "bitcoin_tax_config = {\n",
    "    \"platform_name\": \"Bitcoin.tax\",\n",
    "    \"consolidation_style\": \"direct\", # Use the new direct processing function\n",
    "    \"identification_headers\": [\"Date\", \"Action\", \"Symbol\", \"Volume\", \"Cost/Proceeds\"],\n",
    "    \"column_mapping\": {\n",
    "        \"Date\": \"DateTime_Raw\",\n",
    "        \"Action\": \"Operation_Raw\",\n",
    "        \"Symbol\": \"Currency_Raw\",\n",
    "        \"Volume\": \"Buy_Amount_Raw\",\n",
    "        \"Currency\": \"Pair_Currency_Raw\",\n",
    "        \"Cost/Proceeds\": \"Sell_Amount_Raw\",\n",
    "        \"Fee\": \"Fee_Raw\",\n",
    "        \"FeeCurrency\": \"Fee_Currency_Raw\",\n",
    "        \"Account\": \"Exchange_Raw\",\n",
    "        \"Subaccount\": \"Group_Raw\",\n",
    "        \"ExchangeId\": \"Trade_ID_Raw\",\n",
    "        \"Memo\": \"Comment_Raw\"\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "# --- NEW: Configuration for Binance US (Direct Style) ---\n",
    "binance_us_config = {\n",
    "    \"platform_name\": \"Binance US\",\n",
    "    \"consolidation_style\": \"direct\", # Use the direct processing function\n",
    "    \"identification_headers\": [\"Time\", \"Category\", \"Operation\", \"Base Asset\", \"Quote Asset\"],\n",
    "    \"column_mapping\": {\n",
    "        \"User ID\": \"Group_Raw\",\n",
    "        \"Time\": \"DateTime_Raw\",\n",
    "        \"Category\": \"Category_Raw\",\n",
    "        \"Operation\": \"Operation_Raw\",\n",
    "        \"Order ID\": \"Order_ID_Raw\",\n",
    "        \"Transaction ID\": \"Trade_ID_Raw\",\n",
    "        # Columns for Trades/Swaps\n",
    "        \"Base Asset\": \"Currency_Raw\",\n",
    "        \"Realized Amount For Base Asset\": \"Buy_Amount_Raw\",\n",
    "        \"Quote Asset\": \"Pair_Currency_Raw\",\n",
    "        \"Realized Amount for Quote Asset\": \"Sell_Amount_Raw\",\n",
    "        \"Fee Asset\": \"Fee_Currency_Raw\",\n",
    "        \"Realized Amount for Fee Asset\": \"Fee_Raw\",\n",
    "        # Columns for Deposits/Withdrawals\n",
    "        \"Primary Asset\": \"Primary_Asset_Raw\",\n",
    "        \"Realized Amount For Primary Asset\": \"Primary_Amount_Raw\",\n",
    "        \"Additional Note\": \"Comment_Raw\"\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "# --- NEW: Configuration for MEXC ---\n",
    "mexc_config = {\n",
    "    \"platform_name\": \"MEXC\",\n",
    "    \"consolidation_style\": \"pair\", # Separate pairs before using the direct processing function\n",
    "    \"identification_headers\": [\"Pairs\", \"Time\", \"Side\", \"Executed Amount\", \"Total\"],\n",
    "    \"column_mapping\": {\n",
    "        \"Time\": \"DateTime_Raw\",\n",
    "        \"Side\": \"Operation_Raw\",\n",
    "        \"Pairs\": \"Pair_Raw\",\n",
    "        \"Executed Amount\": \"Buy_Amount_Raw\",\n",
    "        \"Total\": \"Sell_Amount_Raw\",\n",
    "        \"Fee\": \"Fee_Raw\",\n",
    "        \"Role\": \"Comment_Raw\"\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "# --- NEW: Configuration for KuCoin ---\n",
    "kucoin_config = {\n",
    "    \"platform_name\": \"KuCoin\",\n",
    "    \"consolidation_style\": \"pair\", # Separate pairs before direct processing function\n",
    "    \"identification_headers\": [\"UID\", \"Symbol\", \"Side\", \"Filled Amount\", \"Filled Volume\"],\n",
    "    \"column_mapping\": {\n",
    "        \"UID\": \"Group_Raw\",\n",
    "        \"Order ID\": \"Order_ID_Raw\",\n",
    "        \"Symbol\": \"Pair_Raw\",\n",
    "        \"Side\": \"Operation_Raw\",\n",
    "        \"Filled Amount\": \"Buy_Amount_Raw\",\n",
    "        \"Filled Volume\": \"Sell_Amount_Raw\",\n",
    "        \"Filled Time(UTC+00:00)\": \"DateTime_Raw\",\n",
    "        \"Fee\": \"Fee_Raw\",\n",
    "        \"Fee Currency\": \"Fee_Currency_Raw\",\n",
    "        \"Maker/Taker\": \"Comment_Raw\"\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "koinly_config = {\n",
    "    \"platform_name\": \"Koinly\",\n",
    "    \"consolidation_style\": \"direct\", \n",
    "    \"identification_headers\": [\"Date (UTC)\", \"From Wallet (read-only)\", \"From Currency\", \"To Amount\", \"Net Value\"],\n",
    "    \"column_mapping\": {\n",
    "        \"ID (read-only)\": \"Trade_ID_Raw\",\n",
    "        \"Date (UTC)\": \"DateTime_Raw\",\n",
    "        \"Type\": \"Category_Raw\",\n",
    "        \"Tag\": \"Operation_Raw\",\n",
    "        \"From Wallet (read-only)\": \"Group_Raw\",\n",
    "        \"To Amount\": \"Buy_Amount_Raw\",\n",
    "        \"To Currency\": \"Currency_Raw\",\n",
    "        \"From Amount\": \"Sell_Amount_Raw\",\n",
    "        \"From Currency\": \"Pair_Currency_Raw\",\n",
    "        \"Fee Amount\": \"Fee_Raw\",\n",
    "        \"Fee Currency\": \"Fee_Currency_Raw\",\n",
    "        \"Description\": \"Comment_Raw\"\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "awaken_tax_config = {\n",
    "    \"platform_name\": \"Awaken Tax\",\n",
    "    \"consolidation_style\": \"multi\", # Multi blockchain consolidation, with multi variables in single column\n",
    "    \"identification_headers\": [\"Priority\", \"Provider\", \"Title\", \"Hash\", \"Sent\", \"Received\"],\n",
    "    \"column_mapping\": {\n",
    "        \"ID\": \"Trade_ID_Raw\",\n",
    "        \"Priority\": \"Priority_Raw\",\n",
    "        \"Provider\": \"Exchange_Raw\",\n",
    "        \"Title\": \"Operation_Raw\",\n",
    "        \"Date\": \"DateTime_Raw\",\n",
    "        \"Notes\": \"Comment_Raw\",\n",
    "        \"Hash\": \"Hash_Raw\",\n",
    "        \"Cap Gains (USD)\": \"Cap_Gains_Raw\",\n",
    "        \"Sent\": \"Sent_Raw\",\n",
    "        \"Received\": \"Received_Raw\",\n",
    "        \"Fees\": \"Fee_Raw\",\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "stake_tax_config = {\n",
    "    \"platform_name\": \"Stake Tax\",\n",
    "    \"consolidation_style\": \"direct\",\n",
    "    \"identification_headers\": [\"timestamp\", \"tx_type\", \"received_amount\", \"received_currency\", \"sent_amount\", \"sent_currency\", \"fee\", \"fee_currency\"],\n",
    "    \"column_mapping\": {\n",
    "        \"timestamp\": \"DateTime_Raw\",\n",
    "        \"tx_type\": \"Category_Raw\",\n",
    "        \"received_amount\": \"Buy_Amount_Raw\",\n",
    "        \"received_currency\": \"Currency_Raw\",\n",
    "        \"sent_amount\": \"Sell_Amount_Raw\",\n",
    "        \"sent_currency\": \"Pair_Currency_Raw\",\n",
    "        \"fee\": \"Fee_Raw\",\n",
    "        \"fee_currency\": \"Fee_Currency_Raw\",\n",
    "        \"comment\": \"OG_Comment_Raw\",\n",
    "        \"url\": \"Comment_Raw\",\n",
    "        \"exchange\": \"Exchange_Raw\",\n",
    "        \"wallet_address\": \"Group_Raw\",\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "polygon_zkevm_config = {\n",
    "    \"platform_name\": \"Polygon ZKevm\",\n",
    "    \"consolidation_style\": \"direct\",\n",
    "    \"identification_headers\": ['DateTime', 'From', 'From_Nametag', 'To', 'To_Nametag', 'Amount'],\n",
    "    \"column_mapping\": {\n",
    "        \"Transaction Hash\": \"Trade_ID_Raw\",\n",
    "        \"Parent Transaction Hash\": \"Parent_Transaction_ID_Raw\",\n",
    "        \"Status\": \"Status_Raw\",\n",
    "        \"Method\": \"Category_Raw\",\n",
    "        \"DateTime\": \"DateTime_Raw\",\n",
    "        \"From\": \"From_Raw\",\n",
    "        \"To\": \"To_Raw\",\n",
    "        \"Amount\": \"Amount_Cur_Raw\",\n",
    "        \"Txn Fee\": \"Fee_Raw\",\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "nexo_config = {\n",
    "    \"platform_name\": \"Nexo\",\n",
    "    \"consolidation_style\": \"direct\",\n",
    "    \"identification_headers\": [\"Transaction\", \"Type\", \"Input Currency\", \"Input Amount\", \"Output Currency\", \"Output Amount\", \"Fee\", \"Fee Currency\", \"Date / Time (UTC)\"],\n",
    "    \"column_mapping\": {\n",
    "        \"Transaction\": \"Trade_ID_Raw\",\n",
    "        \"Type\": \"Category_Raw\",\n",
    "        \"Input Currency\": \"Currency_Raw\",\n",
    "        \"Input Amount\": \"Buy_Amount_Raw\",\n",
    "        \"Output Currency\": \"Pair_Currency_Raw\",\n",
    "        \"Output Amount\": \"Sell_Amount_Raw\",\n",
    "        \"Fee\": \"Fee_Raw\",\n",
    "        \"Fee Currency\": \"Fee_Currency_Raw\",\n",
    "        \"Details\": \"Comment_Raw\",\n",
    "        \"Date / Time (UTC)\": \"DateTime_Raw\",\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}\n",
    "\n",
    "cointracker_config = {\n",
    "    \"platform_name\": \"CoinTracker\",\n",
    "    \"consolidation_style\": \"direct\",\n",
    "    \"identification_headers\": [\"Date\", \"Type\", \"Received Quantity\", \"Received Currency\", \"Sent Quantity\", \"Sent Currency\", \"Fee Amount\", \"Fee Currency\", \"Sent Wallet\", \"Received Wallet\", \"Transaction Hash\"],\n",
    "    \"column_mapping\": {\n",
    "        \"Date\": \"DateTime_Raw\",\n",
    "        \"Type\": \"Category_Raw\",\n",
    "        \"Received Quantity\": \"Buy_Amount_Raw\",\n",
    "        \"Received Currency\": \"Currency_Raw\",\n",
    "        \"Sent Quantity\": \"Sell_Amount_Raw\",\n",
    "        \"Sent Currency\": \"Pair_Currency_Raw\",\n",
    "        \"Fee Amount\": \"Fee_Raw\",\n",
    "        \"Fee Currency\": \"Fee_Currency_Raw\",\n",
    "        \"Sent Wallet\": \"Exchange_Raw\",\n",
    "        \"Received Wallet\": \"Group_Raw\",\n",
    "        \"Transaction Hash\": \"Comment_Raw\"\n",
    "    },\n",
    "    \"target_columns\": ['Type', 'Buy', 'Cur.', 'Sell', 'Cur..1', 'Fee', 'Cur..2', 'Exchange', 'Group', 'Comment', 'Date'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a6b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Helper Functions for Transformations ---\n",
    "# New function to extract combined datetime string\n",
    "def extract_datetime_combined(dt_str):\n",
    "    if isinstance(dt_str, (pd.Series, pd.Index)):\n",
    "        if not dt_str.empty:\n",
    "            dt_str = dt_str.iloc[0]\n",
    "        else:\n",
    "            return ''\n",
    "    if pd.isna(dt_str) or dt_str == '':\n",
    "        return ''\n",
    "    try:\n",
    "        # Use errors='coerce' to return NaT for unparseable dates\n",
    "        dt_obj = pd.to_datetime(dt_str, errors='coerce')\n",
    "        if pd.isna(dt_obj):\n",
    "            return ''\n",
    "        return dt_obj.strftime('%d-%m-%Y %H:%M:%S')\n",
    "    except Exception as e:\n",
    "        # This block should ideally not be hit with errors='coerce', but good for extreme cases\n",
    "        print(f\"Error formatting datetime '{dt_str}': {e}\")\n",
    "        return ''    \n",
    "\n",
    "def map_transaction_type(raw_type):\n",
    "    if raw_type == 'deposit':\n",
    "        return 'Deposit'\n",
    "    elif raw_type == 'withdrawal':\n",
    "        return 'Withdrawal'\n",
    "    elif raw_type == 'match':\n",
    "        return 'Trade_Leg'\n",
    "    elif raw_type == 'fee':\n",
    "        return 'Fee_Leg'\n",
    "    elif raw_type == 'conversion':\n",
    "        return 'Swap_Leg'\n",
    "    return 'Other'\n",
    "\n",
    "def get_buy_amount_from_leg(raw_type, amount_raw):\n",
    "    amount = float(amount_raw)\n",
    "    if raw_type == 'deposit' or ((raw_type == 'match' or raw_type == 'conversion') and amount > 0):\n",
    "        return abs(amount)\n",
    "    return 0.0\n",
    "\n",
    "def get_sell_amount_from_leg(raw_type, amount_raw):\n",
    "    amount = float(amount_raw)\n",
    "    if raw_type == 'withdrawal' or ((raw_type == 'match' or raw_type == 'conversion') and amount < 0):\n",
    "        return abs(amount)\n",
    "    return 0.0\n",
    "\n",
    "def get_fee_amount_from_leg(raw_type, amount_raw):\n",
    "    amount = float(amount_raw)\n",
    "    if raw_type == 'fee':\n",
    "        return abs(amount)\n",
    "    return 0.0\n",
    "\n",
    "def passthrough(value):\n",
    "    return value\n",
    "\n",
    "# Map action names to helper functions\n",
    "transformation_actions = {\n",
    "    \"extract_datetime_combined\": extract_datetime_combined,\n",
    "    \"map_transaction_type\": map_transaction_type,\n",
    "    \"get_buy_amount_from_leg\": get_buy_amount_from_leg,\n",
    "    \"get_sell_amount_from_leg\": get_sell_amount_from_leg,\n",
    "    \"get_fee_amount_from_leg\": get_fee_amount_from_leg,\n",
    "    \"passthrough\": passthrough,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42ad14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Function for Trade Consolidation (Updated Currency Logic) ---\n",
    "def consolidate_trade_rows(intermediate_df, config):\n",
    "    final_rows = []\n",
    "\n",
    "    # Separate deposits and withdrawals\n",
    "    deposits_withdrawals_df = intermediate_df[\n",
    "        (intermediate_df['Type_Intermediate'] == 'Deposit') |\n",
    "        (intermediate_df['Type_Intermediate'] == 'Withdrawal')\n",
    "    ].copy()\n",
    "\n",
    "    for _, row in deposits_withdrawals_df.iterrows():\n",
    "        new_row = {col: '' for col in config[\"target_columns\"]}\n",
    "        new_row['Type'] = row['Type_Intermediate']\n",
    "        new_row['Date'] = extract_datetime_combined(row['DateTime_Raw'])\n",
    "        new_row['Exchange'] = row['Exchange']\n",
    "        new_row['Group'] = row['Group']\n",
    "        #new_row['Imported From'] = row['Imported From']\n",
    "        #new_row['Add Date'] = row['Add Date']\n",
    "\n",
    "        if row['Type_Intermediate'] == 'Deposit':\n",
    "            new_row['Buy'] = row['Buy']\n",
    "            new_row['Cur.'] = row['Currency_Raw'] # Take raw currency for deposits/withdrawals\n",
    "            new_row['Comment'] = f\"Deposit (Transfer ID: {row['Transfer_ID_Raw']})\"\n",
    "        elif row['Type_Intermediate'] == 'Withdrawal':\n",
    "            new_row['Sell'] = row['Sell']\n",
    "            new_row['Cur..1'] = row['Currency_Raw'] # Take raw currency for deposits/withdrawals\n",
    "            new_row['Comment'] = f\"Withdrawal (Transfer ID: {row['Transfer_ID_Raw']})\"\n",
    "        final_rows.append(new_row)\n",
    "\n",
    "    # Filter for trade and fee legs\n",
    "    trade_legs_df = intermediate_df[\n",
    "        (intermediate_df['Type_Intermediate'] == 'Trade_Leg') |\n",
    "        (intermediate_df['Type_Intermediate'] == 'Fee_Leg')\n",
    "    ].copy()\n",
    "\n",
    "    if not trade_legs_df.empty:\n",
    "        grouped_trades = trade_legs_df.groupby(['Trade_ID_Raw', 'DateTime_Raw'], dropna=False)\n",
    "\n",
    "        for (trade_id_val, datetime_val), group in grouped_trades:\n",
    "            consolidated_row = {col: '' for col in config[\"target_columns\"]}\n",
    "\n",
    "            # Populate common fields\n",
    "            consolidated_row['Type'] = 'Trade'\n",
    "            consolidated_row['Date'] = extract_datetime_combined(datetime_val)\n",
    "            #consolidated_row['Trade ID'] = trade_id_val if pd.notna(trade_id_val) else ''\n",
    "            first_row = group.iloc[0]\n",
    "            consolidated_row['Exchange'] = first_row['Exchange']\n",
    "            consolidated_row['Group'] = first_row['Group']\n",
    "            #consolidated_row['Imported From'] = first_row['Imported From']\n",
    "            #consolidated_row['Add Date'] = first_row['Add Date']\n",
    "\n",
    "            # Aggregate Buy/Sell/Fee amounts\n",
    "            total_buy = group['Buy'].sum()\n",
    "            total_sell = group['Sell'].sum()\n",
    "            total_fee = group['Fee'].sum()\n",
    "\n",
    "            consolidated_row['Buy'] = total_buy if total_buy > 0 else np.nan\n",
    "            consolidated_row['Sell'] = total_sell if total_sell > 0 else np.nan\n",
    "            consolidated_row['Fee'] = total_fee if total_fee > 0 else np.nan\n",
    "\n",
    "            # --- UPDATED CURRENCY DETERMINATION LOGIC ---\n",
    "            # Buy currency: Find the currency from the leg that contributed to total_buy\n",
    "            buy_currency = ''\n",
    "            if total_buy > 0:\n",
    "                buy_leg = group[group['Buy'] > 0]\n",
    "                if not buy_leg.empty:\n",
    "                    buy_currency = buy_leg['Currency_Raw'].iloc[0]\n",
    "            consolidated_row['Cur.'] = buy_currency\n",
    "\n",
    "            # Sell currency: Find the currency from the leg that contributed to total_sell\n",
    "            sell_currency = ''\n",
    "            if total_sell > 0:\n",
    "                sell_leg = group[group['Sell'] > 0]\n",
    "                if not sell_leg.empty:\n",
    "                    sell_currency = sell_leg['Currency_Raw'].iloc[0]\n",
    "            consolidated_row['Cur..1'] = sell_currency\n",
    "\n",
    "            # Fee currency: Find the currency from the leg that contributed to total_fee\n",
    "            fee_currency = ''\n",
    "            if total_fee > 0:\n",
    "                fee_leg = group[group['Fee'] > 0]\n",
    "                if not fee_leg.empty:\n",
    "                    fee_currency = fee_leg['Currency_Raw'].iloc[0]\n",
    "            consolidated_row['Cur..2'] = fee_currency\n",
    "            # --- END UPDATED CURRENCY DETERMINATION LOGIC ---\n",
    "\n",
    "\n",
    "            # Generate comment for consolidated trade\n",
    "            comment_parts = []\n",
    "            if total_buy > 0 and consolidated_row['Cur.']:\n",
    "                comment_parts.append(f\"Buy {total_buy:.8f} {consolidated_row['Cur.']}\")\n",
    "            if total_sell > 0 and consolidated_row['Cur..1']:\n",
    "                comment_parts.append(f\"Sell {total_sell:.8f} {consolidated_row['Cur..1']}\")\n",
    "            if total_fee > 0 and consolidated_row['Cur..2']:\n",
    "                comment_parts.append(f\"Fee {total_fee:.8f} {consolidated_row['Cur..2']}\")\n",
    "\n",
    "            base_comment = f\"Trade (Trade ID: {trade_id_val})\" if pd.notna(trade_id_val) else \"Trade\"\n",
    "            if comment_parts:\n",
    "                consolidated_row['Comment'] = f\"{base_comment}: {', '.join(comment_parts)}\"\n",
    "            else:\n",
    "                consolidated_row['Comment'] = base_comment\n",
    "\n",
    "            final_rows.append(consolidated_row)\n",
    "            \n",
    "    # Process 'Swap' (conversion) legs\n",
    "    swap_legs_df = intermediate_df[intermediate_df['Type_Intermediate'] == 'Swap_Leg'].copy()\n",
    "    if not swap_legs_df.empty:\n",
    "        # Group by Order_ID_Raw (since no Trade ID) and DateTime_Raw\n",
    "        grouped_swaps = swap_legs_df.groupby(['DateTime_Raw'], dropna=False)\n",
    "\n",
    "        for key_tuple, group in grouped_swaps:\n",
    "            datetime_val = key_tuple[0]\n",
    "            consolidated_row2 = {col: '' for col in config[\"target_columns\"]}\n",
    "        \n",
    "            #consolidated_row2['Type'] = 'Swap (non taxable)'\n",
    "            consolidated_row2['Date'] = extract_datetime_combined(datetime_val)\n",
    "            # No Trade ID for swaps, leave it empty\n",
    "            #consolidated_row2['Trade ID'] = ''\n",
    "            first_row = group.iloc[0]\n",
    "            consolidated_row2['Exchange'] = first_row['Exchange']\n",
    "            consolidated_row2['Group'] = first_row['Group']\n",
    "            #consolidated_row2['Imported From'] = first_row['Imported From']\n",
    "            #consolidated_row2['Add Date'] = first_row['Add Date']\n",
    "\n",
    "            total_buy = group['Buy'].sum()\n",
    "            total_sell = group['Sell'].sum()\n",
    "            # No fee for conversions, so total_fee will be 0\n",
    "            total_fee = 0.0\n",
    "\n",
    "            consolidated_row2['Buy'] = total_buy if total_buy > 0 else np.nan\n",
    "            consolidated_row2['Sell'] = total_sell if total_sell > 0 else np.nan\n",
    "            consolidated_row2['Fee'] = total_fee # Ensure fee is 0\n",
    "\n",
    "            buy_currency = ''\n",
    "            if total_buy > 0:\n",
    "                buy_leg = group[group['Buy'] > 0]\n",
    "                if not buy_leg.empty:\n",
    "                    buy_currency = buy_leg['Currency_Raw'].iloc[0]\n",
    "            consolidated_row2['Cur.'] = buy_currency\n",
    "\n",
    "            sell_currency = ''\n",
    "            if total_sell > 0:\n",
    "                sell_leg = group[group['Sell'] > 0]\n",
    "                if not sell_leg.empty:\n",
    "                    sell_currency = sell_leg['Currency_Raw'].iloc[0]\n",
    "            consolidated_row2['Cur..1'] = sell_currency\n",
    "\n",
    "            # Fee currency will be empty as there's no fee\n",
    "            consolidated_row2['Cur..2'] = ''\n",
    "\n",
    "            if buy_currency.lower()==(\"w\" + sell_currency.lower()) or sell_currency.lower()==(\"w\" + buy_currency.lower()):\n",
    "                consolidated_row2['Type'] = 'Swap (non taxable)' # Final type is 'Swap (non taxable)'\n",
    "                base_comment = \"Swap (non taxable)\"\n",
    "                print(\"DEBUG Swap (non taxable) found\")\n",
    "            else:\n",
    "                consolidated_row2['Type'] = 'Trade'\n",
    "                base_comment = \"Trade\"\n",
    "                print(\"DEBUG trade found\")\n",
    "\n",
    "            comment_parts = []\n",
    "            if total_buy > 0 and consolidated_row2['Cur.']:\n",
    "                comment_parts.append(f\"Buy {total_buy:.8f} {consolidated_row2['Cur.']}\")\n",
    "            if total_sell > 0 and consolidated_row2['Cur..1']:\n",
    "                comment_parts.append(f\"Sell {total_sell:.8f} {consolidated_row2['Cur..1']}\")\n",
    "\n",
    "            \n",
    "            if comment_parts:\n",
    "                consolidated_row2['Comment'] = f\"{base_comment}: {', '.join(comment_parts)}\"\n",
    "            else:\n",
    "                consolidated_row2['Comment'] = base_comment\n",
    "\n",
    "            final_rows.append(consolidated_row2)\n",
    "\n",
    "    final_df = pd.DataFrame(final_rows, columns=config[\"target_columns\"])\n",
    "\n",
    "    # Fill NaN values in numeric columns with 0 for cleaner output CSV\n",
    "    for col in ['Buy', 'Sell', 'Fee']:\n",
    "        if col in final_df.columns:\n",
    "            final_df[col] = pd.to_numeric(final_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    print(\"DEBUG Dates\")\n",
    "    print(final_df['Date'])        \n",
    "            \n",
    "    # Create a temporary datetime column for robust sorting\n",
    "    final_df['Sort_DateTime'] = pd.to_datetime(final_df['Date'], format='%d-%m-%Y %H:%M:%S', errors='coerce')\n",
    "    final_df = final_df.sort_values(by='Sort_DateTime').drop(columns=['Sort_DateTime'])\n",
    "\n",
    "    # Explicitly cast the 'Date' column to string to prevent re-formatting by to_csv\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "\n",
    "    print(\"DEBUG Dates\")\n",
    "    print(final_df['Date'])   \n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da47c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Processing Workflows ---\n",
    "# --- WORKFLOW 1: For Leg-Based Formats (like Coinbase Pro) ---\n",
    "def process_to_intermediate_legs(input_df, config):\n",
    "    renamed_df = input_df.rename(columns=config[\"column_mapping\"])\n",
    "    for _, raw_col in config[\"column_mapping\"].items():\n",
    "        if raw_col not in renamed_df.columns:\n",
    "            renamed_df[raw_col] = np.nan\n",
    "\n",
    "    intermediate_df = pd.DataFrame()\n",
    "    intermediate_df['Type_Intermediate'] = renamed_df.apply(\n",
    "        lambda row: transformation_actions[\"map_transaction_type\"](row.get('Transaction_Type_Raw')), axis=1\n",
    "    )\n",
    "    intermediate_df['DateTime_Raw'] = renamed_df['DateTime_Raw']\n",
    "    intermediate_df['Amount_Raw'] = pd.to_numeric(renamed_df['Amount_Raw'], errors='coerce')\n",
    "    intermediate_df['Currency_Raw'] = renamed_df['Currency_Raw']\n",
    "    intermediate_df['Trade_ID_Raw'] = renamed_df['Trade_ID_Raw']\n",
    "    intermediate_df['Order_ID_Raw'] = renamed_df['Order_ID_Raw']\n",
    "    intermediate_df['Transfer_ID_Raw'] = renamed_df['Transfer_ID_Raw']\n",
    "\n",
    "    for target_col, transform_def in config[\"transformations\"].items():\n",
    "        action = transform_def[\"action\"]\n",
    "        source_cols = transform_def[\"source\"]\n",
    "        if isinstance(source_cols, str):\n",
    "            intermediate_df[target_col] = renamed_df.apply(\n",
    "                lambda row: transformation_actions[action](row.get(source_cols)), axis=1\n",
    "            )\n",
    "        else:\n",
    "            intermediate_df[target_col] = renamed_df.apply(\n",
    "                lambda row: transformation_actions[action](*[row.get(col) for col in source_cols]), axis=1\n",
    "            )\n",
    "\n",
    "    for col, value in config[\"static_values\"].items():\n",
    "        intermediate_df[col] = value\n",
    "    #intermediate_df['Add Date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "    return intermediate_df\n",
    "\n",
    "def consolidate_legs_to_final_df(intermediate_df, config):\n",
    "    # This is your original 'consolidate_trade_rows' function\n",
    "    # It remains unchanged, as its logic is sound for its purpose.\n",
    "    final_df = consolidate_trade_rows(intermediate_df, config)\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41326e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WORKFLOW 2 UPGRADED: Direct Processing Function for Pre-Consolidated Formats ---\n",
    "def process_csv_direct(input_df, config):\n",
    "    renamed_df = input_df.rename(columns=config[\"column_mapping\"])\n",
    "    final_rows = []\n",
    "    platform = config[\"platform_name\"]\n",
    "\n",
    "    for _, row in renamed_df.iterrows():\n",
    "        new_row = {col: '' for col in config[\"target_columns\"]}\n",
    "        add_row = {col: '' for col in config[\"target_columns\"]}\n",
    "        add_row2 = {col: '' for col in config[\"target_columns\"]}\n",
    "\n",
    "        # --- Populate Common Fields ---\n",
    "        new_row['Date'] = extract_datetime_combined(row.get('DateTime_Raw'))\n",
    "        #new_row['Trade ID'] = row.get('Trade_ID_Raw', '')\n",
    "        # #new_row['Imported From'] = f\"{platform} CSV\"\n",
    "        #new_row['Add Date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "        maincomment = row.get('Comment_Raw', '')\n",
    "        new_row['Exchange'] = row.get('Exchange_Raw', platform) # Default to platform name, can be overridden\n",
    "        group = str(row.get('Group_Raw', '')).strip() if not pd.isna(row.get('Group_Raw', '')) else ''\n",
    "        if (';' in group):\n",
    "            name, id = group.split(';')\n",
    "            group = name.strip()\n",
    "        new_row['Group'] = group\n",
    "\n",
    "        operation = str(row.get('Operation_Raw', '')).lower()\n",
    "        category = str(row.get('Category_Raw', '')).lower()\n",
    "        new_row['Fee'] = pd.to_numeric(row.get('Fee_Raw'), errors='coerce')\n",
    "        currency = row.get('Currency_Raw', '').strip() if not pd.isna(row.get('Currency_Raw', '')) else ''\n",
    "        pair_currency = row.get('Pair_Currency_Raw', '').strip() if not pd.isna(row.get('Pair_Currency_Raw', '')) else ''\n",
    "        fee_currency = row.get('Fee_Currency_Raw', '').strip() if not pd.isna(row.get('Fee_Currency_Raw', '')) else ''\n",
    "\n",
    "        if (';' in fee_currency):\n",
    "            cur, id = fee_currency.split(';')\n",
    "            fee_currency = cur.strip()\n",
    "        new_row['Cur..2'] = fee_currency\n",
    "\n",
    "        if (';' in currency):\n",
    "            cur, id = currency.split(';')\n",
    "            currency = cur.strip()\n",
    "        if (';' in pair_currency):\n",
    "            cur, id = pair_currency.split(';')\n",
    "            pair_currency = cur.strip()\n",
    "\n",
    "        if config[\"consolidation_style\"] == \"pair\":\n",
    "            # Like MEXC, when we need to handle pairs separately\n",
    "            pair = row.get('Pair_Raw', '')\n",
    "            if pair:\n",
    "                if '_' in pair:\n",
    "                    base, quote = pair.split('_')\n",
    "                elif '-' in pair:\n",
    "                    base, quote = pair.split('-')\n",
    "                elif '/' in pair:\n",
    "                    base, quote = pair.split('/')\n",
    "                elif ';' in pair:\n",
    "                    base, quote = pair.split(';')\n",
    "                else:\n",
    "                    base, quote = pair.split(' ') if ' ' in pair else (pair, '')\n",
    "                \n",
    "                if operation == 'buy':\n",
    "                    new_row['Cur.'] = base.strip()\n",
    "                    new_row['Cur..1'] = quote.strip()\n",
    "                    new_row['Cur..2'] = quote.strip() if fee_currency is None else fee_currency\n",
    "                elif operation == 'sell':\n",
    "                    new_row['Cur.'] = quote.strip()\n",
    "                    new_row['Cur..1'] = base.strip()\n",
    "                    new_row['Cur..2'] = base.strip() if fee_currency is None else fee_currency\n",
    "            else:\n",
    "                new_row['Cur.'] = currency\n",
    "                new_row['Cur..1'] = pair_currency\n",
    "        if category == 'spam':\n",
    "            continue  # Skip spam entries\n",
    "        elif category == 'transfer':\n",
    "            # if both are present, wallet to wallet transfer, add two rows\n",
    "            if currency is not None and currency != '' and pair_currency is not None and pair_currency != '':\n",
    "                new_row['Type'] = 'Deposit'\n",
    "                add_row['Type'] = 'Withdrawal'\n",
    "                if (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0):\n",
    "                    new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                    new_row['Cur.'] = currency\n",
    "                    new_row['Exchange'] = row.get('Group_Raw', '')\n",
    "                if (row.get('Sell_Amount_Raw') is not None and row.get('Sell_Amount_Raw') != 0):\n",
    "                    add_row['Sell'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                    add_row['Cur..1'] = pair_currency\n",
    "                    add_row['Exchange'] = row.get('Exchange_Raw', platform)\n",
    "                final_rows.append(add_row)\n",
    "            elif (currency is not None and currency != '' and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                new_row['Type'] = 'Deposit'\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = currency\n",
    "            elif (pair_currency is not None and pair_currency != '' and (row.get('Sell_Amount_Raw') is not None and row.get('Sell_Amount_Raw') != 0)):\n",
    "                new_row['Type'] = 'Withdrawal'\n",
    "                new_row['Sell'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur..1'] = pair_currency\n",
    "        elif category == 'deposit' or category == 'transfer in' or category == 'top up crypto' or category == 'top up' or category == 'receive':\n",
    "            new_row['Type'] = 'Reward / Bonus' if operation == 'reward' else 'Deposit'\n",
    "            #new_row['Type'] = 'Deposit'\n",
    "            if (row.get('Primary_Asset_Raw') is not None and row.get('Primary_Amount_Raw') is not None):\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Primary_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = row.get('Primary_Asset_Raw')\n",
    "                print(\"DEBUG Deposit found\")\n",
    "            else:\n",
    "                if (currency is not None and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                    new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                    new_row['Cur.'] = currency\n",
    "        elif category == 'withdrawal' or category == 'transfer out' or category == 'send' or category == 'crypto send':\n",
    "            new_row['Type'] = 'Withdrawal'\n",
    "            if (row.get('Primary_Asset_Raw') is not None and row.get('Primary_Amount_Raw') is not None):\n",
    "                new_row['Sell'] = pd.to_numeric(row.get('Primary_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur..1'] = row.get('Primary_Asset_Raw')\n",
    "            else:\n",
    "                if (pair_currency is not None and (row.get('Sell_Amount_Raw') is not None and row.get('Sell_Amount_Raw') != 0)):\n",
    "                    new_row['Sell'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                    new_row['Cur..1'] = pair_currency\n",
    "        elif category == 'spend':\n",
    "            new_row['Type'] = 'Spend'\n",
    "            if (pair_currency is not None and (row.get('Sell_Amount_Raw') is not None and row.get('Sell_Amount_Raw') != 0)):\n",
    "                new_row['Sell'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur..2'] = pair_currency\n",
    "        elif category == 'convert':\n",
    "            if (currency.lower() == \"w\" + pair_currency.lower()) or (pair_currency.lower() == \"w\" + currency.lower()):\n",
    "                new_row['Type'] = 'Swap (non taxable)'  # For conversions of wrapped crypto, we treat them as swaps\n",
    "                # For Binance 'Convert', Base is what you sold, Quote is what you bought\n",
    "                new_row['Sell'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur..1'] = currency\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = pair_currency\n",
    "            else:\n",
    "                new_row['Type'] = 'Trade'\n",
    "                new_row['Sell'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                if not config[\"consolidation_style\"] == \"pair\":\n",
    "                    new_row['Cur..1'] = currency\n",
    "                    new_row['Cur.'] = pair_currency\n",
    "        elif category == 'airdrop':\n",
    "            new_row['Type'] = 'Airdrop'\n",
    "            if (currency is not None and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = currency\n",
    "        elif category == 'gift' or category == 'tip':\n",
    "            new_row['Type'] = 'Gift / Tip'\n",
    "            if (currency is not None and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = currency\n",
    "        elif category == 'referral bonus' or category == 'reward' or category == 'bonus':\n",
    "            new_row['Type'] = 'Reward / Bonus'\n",
    "            if (currency is not None and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = currency\n",
    "        elif category == 'income':\n",
    "            new_row['Type'] = 'Income'\n",
    "            if (currency is not None and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = currency \n",
    "        elif category == 'other income' or category == 'other_income':\n",
    "            new_row['Type'] = 'Other Income'\n",
    "            if (currency is not None and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = currency\n",
    "        elif category == '_self_transfer' or category == '_unknown':\n",
    "            new_row['Type'] = 'Other Fee'      \n",
    "        elif (category == 'staking' or category == 'fixed term interest' \n",
    "            or category == 'staking reward' or category == 'staking_reward' or category == 'stake reward'):\n",
    "            new_row['Type'] = 'Staking'\n",
    "            if (currency is not None and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = currency\n",
    "            comment = row.get('OG_Comment_Raw', '').strip()\n",
    "            if ('undelegated' in comment.lower() and '[' in comment and ']' in comment):\n",
    "                add_row['Type'] = 'Deposit'\n",
    "                add_row['Date'] = extract_datetime_combined(row.get('DateTime_Raw'))\n",
    "                maincomment = 'UNSTAKING     ' + maincomment.strip()\n",
    "                add_row['Comment'] = maincomment\n",
    "                add_row['Exchange'] = row.get('Exchange_Raw', platform)\n",
    "                comment2 = comment.split('[')[1].split(']')[0].split(' ')\n",
    "                add_row2['Type'] = 'Withdrawal'\n",
    "                add_row2['Date'] = extract_datetime_combined(row.get('DateTime_Raw'))\n",
    "                add_row2['Comment'] = maincomment\n",
    "                exchange = row.get('Exchange_Raw', platform)\n",
    "                staking = exchange.lower().replace('blockchain', 'staking') if 'blockchain' in exchange.lower() else 'staking'\n",
    "                add_row2['Exchange'] = staking\n",
    "                if len(comment2) > 2:\n",
    "                    add_row['Buy'] = pd.to_numeric(comment2[1], errors='coerce')\n",
    "                    add_row['Cur.'] = comment2[2].strip()\n",
    "                    add_row2['Sell'] = pd.to_numeric(comment2[1], errors='coerce')\n",
    "                    add_row2['Cur..1'] = comment2[2].strip()\n",
    "                final_rows.append(add_row)\n",
    "                final_rows.append(add_row2)\n",
    "            elif ('delegated' in comment.lower() and '[' in comment and ']' in comment):\n",
    "                add_row['Type'] = 'Withdrawal'\n",
    "                add_row['Date'] = extract_datetime_combined(row.get('DateTime_Raw'))\n",
    "                maincomment = 'STAKING     ' + maincomment.strip()\n",
    "                add_row['Comment'] = maincomment\n",
    "                add_row['Exchange'] = row.get('Exchange_Raw', platform)\n",
    "                comment2 = comment.split('[')[1].split(']')[0].split(' ')\n",
    "                add_row2['Type'] = 'Deposit'\n",
    "                add_row2['Date'] = extract_datetime_combined(row.get('DateTime_Raw'))\n",
    "                add_row2['Comment'] = maincomment\n",
    "                exchange = row.get('Exchange_Raw', platform)\n",
    "                staking = exchange.lower().replace('blockchain', 'staking') if 'blockchain' in exchange.lower() else 'staking'\n",
    "                add_row2['Exchange'] = staking\n",
    "                if len(comment2) > 2:\n",
    "                    add_row['Sell'] = pd.to_numeric(comment2[1], errors='coerce')\n",
    "                    add_row['Cur..1'] = comment2[2].strip()\n",
    "                    add_row2['Buy'] = pd.to_numeric(comment2[1], errors='coerce')\n",
    "                    add_row2['Cur.'] = comment2[2].strip()\n",
    "                final_rows.append(add_row)\n",
    "                final_rows.append(add_row2)\n",
    "        elif category == '_msgdelegate' or category == 'locking term deposit' or category == 'stake':\n",
    "            new_row['Type'] = 'Withdrawal'\n",
    "            maincomment = 'STAKING     ' + maincomment.strip()\n",
    "            add_row['Type'] = 'Deposit'\n",
    "            add_row['Date'] = extract_datetime_combined(row.get('DateTime_Raw'))\n",
    "            add_row['Comment'] = maincomment\n",
    "            exchange = row.get('Exchange_Raw', platform)\n",
    "            staking = exchange.lower().replace('blockchain', 'staking') if 'blockchain' in exchange.lower() else 'staking'\n",
    "            staking = exchange.lower().replace('wallet', 'staking') if 'wallet' in exchange.lower() else 'staking'\n",
    "            add_row['Exchange'] = staking\n",
    "            if (pair_currency is not None and pair_currency != '' and (row.get('Sell_Amount_Raw') is not None and row.get('Sell_Amount_Raw') != 0)):\n",
    "                new_row['Sell'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur..1'] = pair_currency\n",
    "                add_row['Buy'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                add_row['Cur.'] = pair_currency\n",
    "            else:\n",
    "                comment = row.get('OG_Comment_Raw', '').strip().replace('[', '').replace(']', '')\n",
    "                if 'delegated' in comment.lower():\n",
    "                    comment2 = comment.split(' ')\n",
    "                    if len(comment2) > 2:\n",
    "                        new_row['Sell'] = pd.to_numeric(comment2[1], errors='coerce')\n",
    "                        new_row['Cur..1'] = comment2[2].strip()\n",
    "                        add_row['Buy'] = pd.to_numeric(comment2[1], errors='coerce')\n",
    "                        add_row['Cur.'] = comment2[2].strip()\n",
    "            final_rows.append(add_row)\n",
    "        elif 'undelegate' in category or category == 'unlocking term deposit' or category == 'unstake':\n",
    "            new_row['Type'] = 'Deposit'\n",
    "            maincomment = 'UNSTAKING     ' + maincomment.strip()\n",
    "            add_row['Type'] = 'Withdrawal'\n",
    "            add_row['Date'] = extract_datetime_combined(row.get('DateTime_Raw'))\n",
    "            add_row['Comment'] = maincomment\n",
    "            exchange = row.get('Exchange_Raw', platform)\n",
    "            staking = exchange.lower().replace('blockchain', 'staking') if 'blockchain' in exchange.lower() else 'staking'\n",
    "            add_row['Exchange'] = staking\n",
    "            if (currency is not None and currency != '' and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Cur.'] = currency\n",
    "                add_row['Sell'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                add_row['Cur..1'] = currency\n",
    "            else:\n",
    "                comment = row.get('OG_Comment_Raw', '').strip().replace('[', '').replace(']', '')\n",
    "                if 'undelegated' in comment.lower():\n",
    "                    comment2 = comment.split(' ')\n",
    "                    if len(comment2) > 2:\n",
    "                        new_row['Buy'] = pd.to_numeric(comment2[1], errors='coerce')\n",
    "                        new_row['Cur.'] = comment2[2].strip()\n",
    "                        add_row['Sell'] = pd.to_numeric(comment2[1], errors='coerce')\n",
    "                        add_row['Cur..1'] = comment2[2].strip()\n",
    "            final_rows.append(add_row)\n",
    "        elif category == 'interest' or category == 'interest_payment' or category == 'interest payment':\n",
    "            if currency.lower() == 'usd':\n",
    "                continue # Skip USD interest, as it's not crypto\n",
    "\n",
    "            if (currency is not None and (row.get('Buy_Amount_Raw') is not None and row.get('Buy_Amount_Raw') != 0)):\n",
    "                if row.get('Buy_Amount_Raw') > 0:\n",
    "                    new_row['Type'] = 'Interest Income'\n",
    "                    new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                    new_row['Cur.'] = currency\n",
    "                elif row.get('Buy_Amount_Raw') < 0:\n",
    "                    new_row['Type'] = 'Other Fee'\n",
    "                    new_row['Sell'] = abs(pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce'))\n",
    "                    new_row['Cur..1'] = currency\n",
    "        else: # trade\n",
    "            new_row['Type'] = 'Trade'\n",
    "            if operation is None or operation == '' or operation == 'buy':\n",
    "                # If operation is not specified, assume it's normal buy trade\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Sell'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                if not config[\"consolidation_style\"] == \"pair\":\n",
    "                    new_row['Cur.'] = currency\n",
    "                    new_row['Cur..1'] = pair_currency\n",
    "            elif operation == 'sell':\n",
    "                new_row['Sell'] = pd.to_numeric(row.get('Buy_Amount_Raw'), errors='coerce')\n",
    "                new_row['Buy'] = pd.to_numeric(row.get('Sell_Amount_Raw'), errors='coerce')\n",
    "                if not config[\"consolidation_style\"] == \"pair\":\n",
    "                    new_row['Cur..1'] = currency\n",
    "                    new_row['Cur.'] = pair_currency\n",
    "        new_row['Comment'] = maincomment\n",
    "        final_rows.append(new_row)\n",
    "\n",
    "    final_df = pd.DataFrame(final_rows, columns=config[\"target_columns\"])\n",
    "\n",
    "    # Final cleaning and sorting\n",
    "    for col in ['Buy', 'Sell', 'Fee']:\n",
    "        if col in final_df.columns:\n",
    "            final_df[col] = pd.to_numeric(final_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    if not final_df.empty and 'Date' in final_df.columns:\n",
    "        final_df['Sort_DateTime'] = pd.to_datetime(final_df['Date'], format='%d-%m-%Y %H:%M:%S', errors='coerce')\n",
    "        final_df = final_df.sort_values(by='Sort_DateTime', na_position='first').drop(columns=['Sort_DateTime'])\n",
    "        final_df['Date'] = final_df['Date'].astype(str)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c09248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['delegated', '20', 'TIA']\n"
     ]
    }
   ],
   "source": [
    "comment2 = ('claim reward msgdelegate [delegated 20 TIA]').split('[')[1].split(']')[0].split(' ')\n",
    "print(comment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec8577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Main Controller Function ---\n",
    "def process_file(input_df, config):\n",
    "    \"\"\"\n",
    "    Processes the input DataFrame based on the consolidation style specified in the config.\n",
    "    \"\"\"\n",
    "    style = config.get(\"consolidation_style\")\n",
    "\n",
    "    if style == \"by_trade_id_and_time\":\n",
    "        print(f\"Using leg-based consolidation for {config['platform_name']}...\")\n",
    "        # NOTE: 'consolidate_legs_to_final_df' would be your original 'consolidate_trade_rows' function\n",
    "        intermediate_df = process_to_intermediate_legs(input_df, config)\n",
    "        final_df = consolidate_legs_to_final_df(intermediate_df, config)\n",
    "        return final_df\n",
    "        \n",
    "    elif style == \"direct\" or style == \"pair\":\n",
    "        print(f\"Using direct processing for {config['platform_name']}...\")\n",
    "        final_df = process_csv_direct(input_df, config)\n",
    "        return final_df\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown consolidation_style: '{style}' in config for {config['platform_name']}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcb925d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using leg-based consolidation for Coinbase Pro...\n",
      "DEBUG trade found\n",
      "DEBUG trade found\n",
      "DEBUG trade found\n",
      "DEBUG trade found\n",
      "DEBUG trade found\n",
      "DEBUG trade found\n",
      "DEBUG Dates\n",
      "0      06-10-2017 23:13:16\n",
      "1      12-10-2017 19:59:32\n",
      "2      15-10-2017 16:47:59\n",
      "3      16-10-2017 15:08:21\n",
      "4      21-10-2017 14:50:41\n",
      "              ...         \n",
      "644    06-02-2021 23:24:41\n",
      "645    09-02-2021 04:35:34\n",
      "646    10-02-2021 00:49:23\n",
      "647    13-04-2021 05:41:08\n",
      "648    11-02-2022 16:28:23\n",
      "Name: Date, Length: 649, dtype: object\n",
      "DEBUG Dates\n",
      "0      06-10-2017 23:13:16\n",
      "1      12-10-2017 19:59:32\n",
      "2      15-10-2017 16:47:59\n",
      "150    15-10-2017 21:12:18\n",
      "151    15-10-2017 21:13:43\n",
      "              ...         \n",
      "130    02-12-2022 22:25:39\n",
      "131    02-12-2022 22:25:51\n",
      "132    02-12-2022 22:25:59\n",
      "133    02-12-2022 22:26:05\n",
      "134    02-12-2022 22:26:10\n",
      "Name: Date, Length: 649, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "\n",
    "# Assume 'df_coinbase_pro' is a DataFrame loaded from a Coinbase Pro CSV\n",
    "df_coinbase_pro = pd.read_csv('Combined_Coinbase_Pro_2017_2022 (1).csv')\n",
    "final_cb_df = process_file(df_coinbase_pro, coinbase_pro_config)\n",
    "final_cb_df.to_csv('coinbase_pro_formatted2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d40540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for Bitcoin.tax...\n"
     ]
    }
   ],
   "source": [
    "# Assume 'df_bitcoin_tax' is a DataFrame loaded from your Bitcoin.tax CSV\n",
    "df_bitcoin_tax = pd.read_csv('Bitcoin.tax 2018.csv')\n",
    "final_bt_df = process_file(df_bitcoin_tax, bitcoin_tax_config)\n",
    "final_bt_df.to_csv('bitcoin_tax_formatted2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8d03e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for Binance US...\n"
     ]
    }
   ],
   "source": [
    "# Assume 'df_binance_us' is a DataFrame loaded from a Binance US CSV\n",
    "df_binance_us = pd.read_csv('Binance US report 2-23 to 2-24 (1).csv')\n",
    "final_binance_df = process_file(df_binance_us, binance_us_config)\n",
    "final_binance_df.to_csv('binance_us_formatted2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "508da14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for MEXC...\n"
     ]
    }
   ],
   "source": [
    "# Assume 'df_mexc_us' is a DataFrame loaded from a MEXC excel\n",
    "excelFile = pd.read_excel('MEXC Trade History-4-9-23 TO 4-8-24.xlsx')\n",
    "df_mexc_us = pd.DataFrame(excelFile)\n",
    "final_mexc_df = process_file(df_mexc_us, mexc_config)\n",
    "final_mexc_df.to_csv('mexc_formatted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4157e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for KuCoin...\n"
     ]
    }
   ],
   "source": [
    "# Assume 'df_kucoin_us' is a DataFrame loaded from a Kucoin CSV\n",
    "df_kucoin_us = pd.read_csv('Spot Orders_Completed Trades.csv')\n",
    "final_kucoin_df = process_file(df_kucoin_us, kucoin_config)\n",
    "final_kucoin_df.to_csv('kucoin_formatted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf0a1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for Koinly...\n"
     ]
    }
   ],
   "source": [
    "df_koinly_us = pd.read_csv('Koinly export Sui.csv')\n",
    "final_koinly_df = process_file(df_koinly_us, koinly_config)\n",
    "final_koinly_df.to_csv('koinly_formatted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee234c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for Koinly...\n"
     ]
    }
   ],
   "source": [
    "df_koinly2 = pd.read_csv('Koinly ZKsync and ADA.csv')\n",
    "final_koinly2_df = process_file(df_koinly2, koinly_config)\n",
    "final_koinly2_df.to_csv('koinly_ADA_formatted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307a5bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for Stake Tax...\n"
     ]
    }
   ],
   "source": [
    "df_stake_tax_us = pd.read_csv('Stake.tax Celestia export.csv')\n",
    "final_stake_tax_df = process_file(df_stake_tax_us, stake_tax_config)\n",
    "final_stake_tax_df.to_csv('stake_tax_formatted2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe259ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for Nexo...\n"
     ]
    }
   ],
   "source": [
    "df_nexo_us = pd.read_csv('nexo_transactions (2).csv')\n",
    "final_nexo_df = process_file(df_nexo_us, nexo_config)\n",
    "final_nexo_df.to_csv('nexo_formatted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0633e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using direct processing for CoinTracker...\n"
     ]
    }
   ],
   "source": [
    "df_cointracker_us = pd.read_csv('Cointracker William Pugh.csv')\n",
    "final_cointracker_df = process_file(df_cointracker_us, cointracker_config)\n",
    "final_cointracker_df.to_csv('cointracker_formatted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a941285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the two DataFrames equal? False\n",
      "Empty DataFrame\n",
      "Columns: [Type, Buy, Cur., Sell, Cur..1, Fee, Cur..2, Exchange, Group, Comment, Trade ID, Imported From, Add Date, Date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check differences of old and new\n",
    "t1 = pd.read_csv('bitcoin_tax_formatted.csv')\n",
    "t2 = pd.read_csv('bitcoin_tax_formatted2.csv')\n",
    "are_equal = t1.equals(t2)\n",
    "print(f\"Are the two DataFrames equal? {are_equal}\")\n",
    "different_rows = t1[t1 != t2].dropna()\n",
    "print(different_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
